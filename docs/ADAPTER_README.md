# Universal LLM API Adapter

A unified interface for all major LLM providers with multimodal support.

## Quick Start

```python
from utils.llm_helpers import generate_with_llm

# Text generation
response = generate_with_llm(
    prompt="Explain machine learning",
    provider="gemini",
    temperature=0.7
)

print(response.text)
```

## Supported Providers

| Provider | Vision | Streaming | Models |
|----------|--------|-----------|--------|
| ğŸ¤– OpenAI | âœ… | âœ… | GPT-4o, GPT-4 Turbo, GPT-3.5 |
| ğŸ§  Anthropic | âœ… | âœ… | Claude 3.5 Sonnet, Opus, Haiku |
| âœ¨ Google Gemini | âœ… | âœ… | Gemini 2.0, 1.5 Pro/Flash |
| ğŸ”· Cohere | âŒ | âœ… | Command R+, Command R |
| ğŸ”€ OpenRouter | âœ… | âœ… | 50+ models |
| â˜ï¸ Azure OpenAI | âœ… | âœ… | GPT-4o, GPT-4 Turbo |
| ğŸ¤— Hugging Face | âŒ | âœ… | Llama 3, Mistral, Mixtral |

## Installation

```bash
pip install -r requirements.txt
```

## Configuration

Add API keys to `.env`:

```bash
GEMINI_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here
ANTHROPIC_API_KEY=your_key_here
# ... etc
```

## Documentation

See [LLM_ADAPTER_GUIDE.md](LLM_ADAPTER_GUIDE.md) for complete documentation.

## Examples

```bash
python examples/adapter_demo.py
```

## Features

- âœ… Unified interface for all providers
- âœ… Automatic multimodal support
- âœ… Cost tracking and token counting
- âœ… Error handling with retries
- âœ… Model capability detection
- âœ… Easy provider switching
